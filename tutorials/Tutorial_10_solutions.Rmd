---
title: "Lab 10 - Random Effects: two or more factors in R"
output: html_document
    number_sections: yes
    toc: yes
    toc_float: yes
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Note: you can download the .Rmd file using the 'code' button on the top right.

# Mixed Model - Example (From Aho, page 464)

Let us reconsider the potato experiment with variety as a random factor and fertilizer as a fixed factor. It is reasonable to define variety as a random factor. There are over 4000 potato varieties, and inference to such a population might be of interest. 

Here we have 2 factors:

Fertilizer – fixed factor

Varieties – random factor

The interaction between fertilizer and Varieties is a random factor too (as at least one of them is random). So, the variance components are:

$$Var(Y_{ijk})=\sigma_{Variety}^2+\sigma_{Variety:Fert}^2+\sigma_{\epsilon}^2$$

A model including both fixed and random factors is called *mixed model*.


Now, let us calculate the ANOVA variance components. When we have one fixed and one random factor the anova estimators for a balanced two-way factorial design are given in the following table.

For A fixed and B random

| Source | Expected mean squares | ANOVA estimators |
|:-------|:---------------------------------------------------------------------------------------------------------------------------------------------:|---------:|
| A      | $E(MS_A)=\sigma_{\epsilon}^2 + n\sigma_{\alpha\beta}^2 + bn\frac{\sum \alpha^2}{a-1}$                                                         |          |
| B      | $E(MS_B) = \sigma_{\epsilon}^2 + an\sigma_{\beta}^2$                                  | $\hat\sigma_{\beta}^2= \frac{MS_B - MS_{\epsilon}}{an}$ |
| A:B    | $E(MS_{A:B})= \sigma_{\epsilon}^2 + n\sigma_{\alpha\beta}^2$                          | $\hat\sigma_{(\alpha\beta)}^2=\frac{MS_{A:B} - MS_E}{n}$         |
| Error  | $E(MS_E)=\sigma_{\epsilon}^2$                                                         | $\hat\sigma_{\epsilon}^2= MS_E$                       |


Fitting the classical two-way ANOVA model:

```{r, echo=TRUE}
library(asbio)
data(potato)
# If you can't load asbio package you can download "potato.txt" from STREAM and
#load this data with the folowing command
#potato <- read.table("potato.txt")
m1 <- aov(Yield~Variety*Fert,data=potato)
anova(m1)
```

Computing the variance components.

```{r, echo=TRUE}
MSF <- 0.7170
MSV <- 3.9671
MSFV <- 0.0910
MSE <- 0.3420
n=3 #3 replicates for each combination of levels
a=3 # number of levels in the fixed factor A (Fert)
```

```{r, echo=TRUE}
(MSV-MSE)/(a*n) # Variance component for Variety

(MSFV-MSE)/n # Variance component for Fert:Variety

MSE # Variance component for error
```

We see that one of our estimates is negative. 

Let us fit the model using `lmer` function.

```{r, echo=TRUE}
library(lme4)
potato.ref <- lmer(Yield ~ Fert + (1|Variety) + (1|Variety : Fert), data = potato)
potato.ref
```

In this case, the REML variance estimates are not equal to the ANOVA method estimates, which gives negative results.


To determine the significance of the fixed fertilizer factor, we would perform a likelihood ratio test with model likelihoods based on ML estimates. This is most easily done with the function update.

```{r, echo=TRUE} 
pot.ref.ML <- update(potato.ref, REML = FALSE) 
pot.nested.1 <- update(potato.ref, ~. - Fert, REML = FALSE) 
anova(pot.ref.ML, pot.nested.1) 
```


The test and information-theoretic criteria indicate that fertilizer has only marginal importance to yield. 

Next, we test for the importance of variety, and the interaction of fertilizer and variety, both of which are random. To accomplish this, we test the hypotheses 

$H_0: \sigma_{Variety:Fert}^2= 0$ and 
$H_0: \sigma_{Variety}^2= 0$ 


For the first hypothesis, $H_0: \sigma_{Variety:Fert}^2= 0$, we create a nested model without the variety:fertilizer interaction.

```{r,echo=TRUE}
pot.nested2 <- update(potato.ref, ~.-(1| Variety:Fert))
```

We then calculate the likelihood ratio test statistic by finding 2 times the difference in log-likelihoods of the reference model and `pot.nested2` model (both fitted via REML). 

```{r,echo=TRUE,eval=FALSE}
G2=2*(as.numeric(summary(potato.ref)$logLik) - as.numeric(summary(pot.nested2)$logLik))
```


We find that

$$G^2=2\left[l(R)-l(N)\right]\approx0$$
If $H_0$ is true, then $G^2$ will be a random outcome from a mixture of $\chi_1^2$ and $\chi_2^2$ distributions. Thus we calculate p-value as 

`p-value = 0.5*pchisq(G2,df=1,lower.tail = FALSE)+0.5*pchisq(G2,df=2,lower.tail = FALSE)`

In this case, note that $G^2\approx0$, making the P-value approximately 1, and prompting both failure to reject $H_0$ and deletion of the interaction term. 

To test $H_0: \sigma_{Variety}^2= 0$, we create a nested model (within `pot.nested2`) without the variety factor. We use `gls` since this model will be without random effects.

```{r, echo=TRUE}
detach(package:lme4, unload=TRUE)
library(nlme) 
pot.nested3 <- gls(Yield ~ Fert, data = potato)
summary(pot.nested3)
```

We then find 2 times the difference in log-likelihood of `pot.nested2` and `pot.nested3` (both fitted via `REML`). 

This is $G2 = 2[−102.6 + 133.22] = 61.24$. 

The P-value allows clear-cut rejection of $H_0$ even without division by 2 to address the  $\chi_1^2$ and $\chi_0^2$ mixture distribution under H0.

```{r, echo=TRUE}
pchisq(61.24,1,lower.tail = F)
```


```{r, echo=TRUE}
#This is how we would calculate a better approximation to the p-value, addressing the mixture #distriution 
0.5*pchisq(61.24,1,lower.tail = F) + 0.5*pchisq(61.24,0,lower.tail = F)
```

## Exercise

The `Tree.txt` dataset available on STREAM refers to a two-way factorial design experiment where a researcher investigated the influence of device and operator on the trees height measurements.  Five different types of devices were combined with four operators resulting in 20 combinations (treatments). Each treatment was repeated 10 times, i.e.  each combination of device and operator was used to measure 10 trees. 


a)	Read the dataset into R and name the data.frame as “Tree”. You will need to change the data format from “wide” to “long”. Use the following commands to do so.

```{r, eval=TRUE}
# Set your own working directory
# setwd("C:/Users/ricar/Documents/Biostatistics/Module 3 - Mixed models/Tutorials")
Trees <- read.table("Trees.txt", header = TRUE)
```

```{r}
library("tidyr") 
dtl <- Trees %>% pivot_longer(c("I", "II", "III", "IV", "V", "VI", "VII", "VIII", "IX", "X" ), names_to = "Tree", values_to="Hight")

dtl
```


For the following analysis ignore the column `Tree`.

b) One factor will be treated as random and the other as fixed.	Which one should be treated as random and which should be fixed? Give reasons.

c)	Fit a two-way factorial design linear model (use `lmer` function), including the `Device`, `Operator` and `Device:Operator` terms, and find the REML variance components estimates. Do the radom effects contribute to explain variability on tree hights?

d) In the above analysis we haven't included the `Tree` effect. Assuming there is no interaction between `Tree` and the other factors, adjust the above model again including `Tree` as a random effect. Find the REML variance components estimates. How do they compare to those you found in c)?


e)	Using the model in d) as a reference model test the significance of the random interaction term. 

f)	Assuming `Tree` as the only random effect to be included in your model, test the significance of the fixed factor.

## Solution

b) Operator is treated as random, in general we don't want to draw conclusions to those specific operators. Of primary interest is to estimate the variability associated to this factor. On the other hand device is fixed as our interest is to compare those specific five devices.

c)	Fit a two-way factorial design linear model (use `lmer` function), including `Device`, `Operator` and `Device:Operator`, and find the REML variance components estimates. Do the radom effects contribute to explain variability on tree hights?

```{r, echo=TRUE}
library(lme4)
tree.m1 <- lmer(Hight ~ Device + (1|Operator) + (1|Operator : Device), data = dtl)
summary(tree.m1)
```

The REML variance estimates of the random effects `Operator:Device` and `Operator` are zero. It seems that these random effects don't contribute to explain variability on tree heights. 

d) In the above analysis we haven't included the `Tree` effect. Assuming there is no interaction between `Tree` and the other factors, adjust the above model again including `Tree` as a random effect. Find the REML variance components estimates.  How do they compare to those you found in c)?

```{r, echo=TRUE}
library(lme4)
tree.m2 <- lmer(Hight ~ Device + (1|Operator) + (1|Operator : Device) + (1|Tree), data = dtl)
summary(tree.m2)
```
We observe a great reduction in the residual variance. 
In fact, the `tree` factor acts as a block, that is, we have a factorial experiment in a complete randomized block design.
Including `tree` in our model we reduce residual variability by accounting for heterogeity among trees. 


e) Using the model in d) as a reference model test the significance of the random interaction term. 

To test the hypothesis, $H_0: \sigma_{Operator:Device}^2= 0$, we create a nested model without the `Operator:Device` interaction.

```{r,echo=TRUE}
tree.m3 <- update(tree.m2, ~.-(1| Operator:Device))
```

We then calculate the likelihood ratio test statistic

```{r}
G2=2*(as.numeric(summary(tree.m2)$logLik) - as.numeric(summary(tree.m3)$logLik))
```

and the corresponding `p-value`

```{r}
0.5*pchisq(G2,df=2,lower.tail = FALSE)+0.5*pchisq(G2,df=3,lower.tail = FALSE)
```
The `p-value > 0.20` suggests we don't have enough evidence to keep the interaction term in the model. 

You may want to test the significance of the the random effect `Device` as well. In this case model `m3` will be the referece model.  

```{r,echo=TRUE}
tree.m4 <- update(tree.m3, ~.-(1| Operator))
```

```{r}
G2=2*(as.numeric(summary(tree.m3)$logLik) - as.numeric(summary(tree.m4)$logLik))
```

```{r}
0.5*pchisq(G2,df=2,lower.tail = FALSE)+0.5*pchisq(G2,df=1,lower.tail = FALSE)
```
As expected you would conclued that variability due to operators is negligible.

f)	Assuming `Tree` as the only random effect to be included in your model, test the significance of the fixed factor.

To determine the significance of the fixed `Device` factor, we will perform a likelihood ratio test with model likelihoods based on ML estimates.

Our reference model will include both the fixed `Device` factor and random `Tree` factor.

```{r}
tree.ref.ML <- lmer(Hight ~ Device + (1|Tree), REML = "FALSE", data=dtl)
```

Nested model:
```{r}
tree.nested.ML <- update(tree.ref.ML, ~. -Device,REML="FALSE")
```


```{r}
anova(tree.ref.ML, tree.nested.ML) 
```

The small `p-value` suggests there is a significante `Device` effect.
