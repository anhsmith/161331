---
title: "161331 Week 12 Computer Tutorial"
subtitle: "Analysis of longitudinal data"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_float: yes
    df_print: paged
    code_download: true
  pdf_document:
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up {-}

```{r loadlib, message=FALSE}
library(tidyverse)
library(glmmTMB)
library(marginaleffects)
theme_set(theme_bw())
```


# Soil temperature profiles with depth {-}

We will analyse data on the temperatures of soil at 6 different depths (5, 10, 15, 20, 25 and 30 cm below the surface) at 56 different locations. There are three variables: `temperature` (continuous), `depth` (continuous, but regular), and `location` (factor).

# Load the `temp` data

Read in the dataset “temp2.csv” and assign to object `temp`. 

```{r message=FALSE}
temp <- read_csv('https://raw.githubusercontent.com/anhsmith/161331/main/data/temp2.csv') |> 
  # make location a factor
  mutate(location = as_factor(location)) |> 
  # order levels by maximum temp
  mutate(location = fct_reorder(location,temperature,mean))
temp
str(temp)
```

# Initial plots

Let's plot all the data as depth by temperature.

```{r fig.dim=c(5,3)}
# set up the basic ggplot object, 'gt'
gt <- ggplot(temp) + aes(x = depth, y = temperature)

# call gt and add jittered points
gt + geom_jitter(width = 0.5, alpha = .4) # alpha makes the points transparent
```

Let's add some trend lines.

```{r fig.dim=c(5,3), message=FALSE}
gt + 
  geom_jitter(width = 0.5, alpha = .4) +
  geom_smooth() +                     # add smooth line in blue
  geom_smooth(method = "lm", col = 2) # add linear fit in red

```

Do you think that the linear fit does a good job, or do you think a model with some curvature will be better?

The above plots give us a useful impression of the overall pattern in the data, but they ignore an important structure in the data: the locations. Each location has it's own temperature profile across the range of depths.

Let's plot the locations as individual lines:

```{r fig.dim=c(8,5)}
gt + geom_line(aes(col=location), alpha = .4)
```

Alternatively, we can plot the locations as individual panels.

```{r facet_plot1, fig.dim=c(8,8)}
gw <- gt + facet_wrap( ~ location) 

gw + geom_point()
```

Things to note:

 1. Temperature declines with depth at all locations.
 2. There seems to be some curvature (non-linear) trend in the decline in temperature with depth.
 3. The starting temperature (at 5 m depth) varies a lot across the locations.
 4. The rate of decline varies across the locations.
 5. The rate of decline seems to be steeper for locations that start warmer. We might expect the random effects of locations on intercepts to be correlated with the random effects of locations on slopes.

These observations give us an idea of what sort of things we might include in our model.


# Explanatory *vs* predictive modelling

In general, statistical models have two primary purposes: explanation and prediction. 

We can use models to describe and explain patterns and relationships in our world. If we are doing hypothesis testing (testing whether an effect is non-zero), then we're usually be fitting a model for explanatory purposes. For example, we might be interested in testing for different effects of treatments on the severity of an illness, or to see whether the population of some endangered species has increased or decreased after a decade of monitoring. With these models, there is often a particular variable, or set of variables, that are of primary interest. The model might also include other variables that are not so interesting to us, but we include them because we know they are important in explaining variation in our response variable, or we want to condition on those variables when evaluating the more interesting effects. 

Predictive modelling is less about quantifying evidence for some relationship or effect (as in a hypothesis test), and more about building a model that can be used to make predictions for new data. We would usually use tools like AIC to choose the 'best' predictive model from a set of candidate models. Generally, the predictive accuracy will be greatest if the model structure is a good approximation of the processes that generated the data.

The idea of the present modelling exercise is more about predictive modelling. There is no treatment variable, for example. We know already that temperature declines as we go deeper. We just want to fit a 'good' model, perhaps with the objective of predicting the temperature at new locations with some appropriate level of uncertainty.

# Models that treat depth as continuous for fixed and random effects

## Model 1.1: Linear model with random intercepts (`lm_ri`)

We are going to start off with a relatively simple model and successively add terms to make it more complicated as required. This is a forward model-selection process. 

Our first model will no doubt be too simple. We'll start by modelling temperature as a linear function of depth at the population level, and have a random effect of locations on the intercept. 

### Mathematical description of model `lm_ri`

$$
y_{ij} = \alpha + a_i + \beta x_{ij} + \varepsilon_{ij} \\
a_{i} \sim \text{N}(0,\sigma_a^2) \\
\varepsilon_{ij} \sim \text{N}(0,\sigma_\varepsilon^2)
$$

where

$~~~~~~y_{ij}$ is the temperature at location $i$, observation $j$,

$~~~~~~x_{ij}$ is the depth at location $i$, observation $j$,

$~~~~~~\alpha$ is the population-level intercept (overall mean of $y$ at $x=0$),

$~~~~~~\beta$ is the population-level slope (overall mean change in $y$ per one-unit change in $x$),

$~~~~~~a_i$ are the random effects of locations on the intercept,

$~~~~~~\sigma_a^2$ is variance of $a_i$,

$~~~~~~\sigma_\varepsilon^2$ is error variance. 

### Fitting the model `lm_ri`

```{r}
lm_ri <- glmmTMB(temperature ~ depth + (1 | location), temp)
summary(lm_ri)
```

The mean squared error is 0.679. AIC score (a measure of how bad out-of-sample predictions will be) is 935.6.

### Plotting the predictions and residuals from `lm_ri`

Let's extract the predictions and plot them atop the data.

```{r, fig.dim=c(8,8)}
gw + geom_point() + geom_line(aes(y=predict(lm_ri)), col=2)  +
  ggtitle("Predictions by location")
```



You might be able to see in this model that the slopes of the lines are the same for each location, but the heights (intercepts) differ. They are therefore parallel.

```{r fig.dim=c(8,5)}
gt + 
  geom_line(aes(y=predict(lm_ri),col=location), alpha=.6) + 
  geom_point(aes(col=location), alpha = .6)  +
  ggtitle("Predictions")
```

This model is a good start, but there is certainly room for improvement.

Let's take a look at the residuals.

```{r, fig.dim=c(8,8)}
gw + 
  geom_hline(yintercept = 0) +
  geom_point(aes(y=residuals(lm_ri))) +
  ggtitle("Residuals by location")
```

Those are some baaaaad residuals. Almost every location has some pattern in the residuals. There is plenty of evidence of curvature. Let's do something about that.

## Model 1.2: Quadratic (second-order polynomial) model with random intercepts (`qm_ri`)

We can see that `temperature` has a curvilinear relationship with `depth`, so we'll use a polynomial. We'll retain the random intercepts for `location`.

### Mathematical description of model `qm_ri`

$$
y_{ij} = \alpha + a_i + \beta_1 x_{ij} + \beta_2 x^2_{ij} + \varepsilon_{ij} \\
a_{i} \sim \text{N}(0,\sigma_a^2) \\
\varepsilon_{ij} \sim \text{N}(0,\sigma_\varepsilon^2)
$$

where


$~~~~~~y_{ij}$ is the temperature at location $i$, observation $j$,

$~~~~~~x_{ij}$ is the depth at location $i$, observation $j$,

$~~~~~~x^2_{ij}$ is the *squared* depth at location $i$, observation $j$,

$~~~~~~\alpha$ is the population-level intercept (overall mean of $y$ at $x=0$),

$~~~~~~\beta_1$ is the population-level slope for $x_{ij}$, the linear effect,

$~~~~~~\beta_2$ is the population-level slope for $x^2_{ij}$, the quadratic effect, 

$~~~~~~a_i$ are the random effects of locations on the intercept,

$~~~~~~\sigma_a^2$ is variance of $a_i$,

$~~~~~~\sigma_\varepsilon^2$ is error variance. 


### Orthogonal vs raw polynomials

Instead of fitting the 'raw' polynomial, `temperature ~ depth + I(depth^2) + ...`, we will use the `poly()` function `temperature ~ poly(depth,2) + ...`. 

The `poly()` function converts your *x*-variable into two new variables: a linear one and a quadratic one. It does so in a way that the two variables are *orthogonal*, or uncorrelated. The predictor variable representing $x$ is not correlated with the predictor variable representing $x^2$.

Here are the raw and orthogonal versions of $x$ and $x^2$.

```{r}
Depths <- tibble(`Raw depth` = temp$depth) |> 
  mutate(
    `Raw depth squared` = `Raw depth`^2,
    `Orthogonal depth` = poly(`Raw depth`,2)[,1],
    `Orthogonal depth squared` = poly(`Raw depth`,2)[,2]
    ) |> 
  distinct(`Raw depth`, .keep_all= TRUE)

Depths
```

Let's plot them against each other.

```{r message=FALSE, fig.dim=c(8,8)}
Depths |> GGally::ggpairs(diag = list(continuous = "blank"))
```

You can see that *orthogonal* depth squared isn't correlated with either *raw* depth or  *orthogonal* depth. In contrast, *raw* depth squared is very strongly correlated with *raw* depth. 

Why is this preferable? 

The raw quadratic `x^2` increases with `x`. Because they are correlated, you get all the issues associated with having correlated predictors (multicollinearity). The standard errors of both coefficients gets inflated. The `x^2` term captures some of the linear relationship that should be attributed to linear `x` term. The linear trend is spread between the two terms.

When orthogonal polynomials are used, the *linear trend* component is captured by the `poly(x,2)1`  term and the *curvature* component is captured by the `poly(x,2)2` term. Each job is done separately by a single term. This can help to clarify the process model selection. 

A potential down side is that it changes the direct interpretability of the coefficients, but that's ok. In general, I'm more comfortable with having the interpretation of a model independent from the parameterisation of a model. 

One more thing: personally, I never fit anything more than a second-order polynomial ($x$ and $x^2$ ok, but not $x^3$). Any higher and the fit becomes extremely unreliable. And there are usually better options.

### Fitting the model `qm_ri`

```{r}
qm_ri <- glmmTMB(temperature ~ poly(depth,2) + (1|location), data=temp)
summary(qm_ri)
```

Both the linear and quadratic polynomial terms are very strongly significant. The fit has improved a lot, with a mean square residual has reduced from 0.679 to 0.42.

As an aside, let's look at the raw polynomial model.

```{r}
glmmTMB(temperature ~ depth + I(depth^2) + (1|location), data=temp) |> summary()
```

The coefficients have changed, but the model remains essentially the same. Any predictions will be identical to `qm_ri`. It is the same model when considered wholistically, just parameterised in a different way. Therefore, the mathematical description of this model that I gave above is not exactly correct (with respect to the $\beta_1$ and $\beta_2$ terms), but overall it is the same model.

### Plotting the predictions and residuals from `qm_ri`

Let's plot the predictions on the data.

```{r, fig.dim=c(8,8)}
gw + geom_point() + geom_line(aes(y=predict(qm_ri)), col=2)  +
  ggtitle("Predictions by location")
```

The lines are now curved but they're still parallel, because there is still no random effect of locations on the slope.

```{r fig.dim=c(8,5)}
gt + 
  geom_line(aes(y=predict(qm_ri),col=location), alpha=.6) + 
  geom_point(aes(col=location), alpha = .6)  +
  ggtitle("Predictions")
```


```{r, fig.dim=c(8,8)}
gw + 
  geom_hline(yintercept = 0) +
  geom_point(aes(y=residuals(qm_ri))) +
  ggtitle("Residuals by location")
```

These residuals are still bad. It seems we will need different slopes for different folks (well, locations, at least). 



## Model 1.3: Polynomial model with random intercepts and random slopes for linear term (`qm_ris`)

Let's fit a second-order polynomial model at the population level, and allow the intercept and linear effects of depth to differ among locations.

### Mathematical description of model `qm_ris`

$$
y_{ij} = \alpha + a_i + \beta_1 x_{ij} + b_{1i} x_{ij} + \beta_2 x^2_{ij} + \varepsilon_{ij} \\
\begin{equation}
\begin{bmatrix}
  a_i \\
  b_{1i} 
  \end{bmatrix}
\sim \text{MVN}(\begin{bmatrix}
  0 \\
  0\\
  \end{bmatrix},
\begin{bmatrix}
  \sigma^2_a & \\
  \sigma_{ab_1} & \sigma^2_{b_1} \\
  \end{bmatrix}
)
\end{equation} \\
\varepsilon_{ij} \sim \text{N}(0,\sigma_\varepsilon^2)
$$

where

$~~~~~~y_{ij}$ is the temperature at location $i$, observation $j$,

$~~~~~~x_{ij}$ is the depth at location $i$, observation $j$,

$~~~~~~x^2_{ij}$ is the *squared* depth at location $i$, observation $j$,

$~~~~~~\alpha$ is the population-level intercept (overall mean of $y$ at $x=0$),

$~~~~~~\beta_1$ is the population-level slope for $x_{ij}$, the linear effect,

$~~~~~~\beta_2$ is the population-level slope for $x^2_{ij}$, the quadratic effect, 

$~~~~~~a_i$ are the random effects of locations on the intercept,

$~~~~~~b_{1i}$ are the random effects of locations on the linear effect of $x_{ij}$,

$~~~~~~\sigma_a^2$ is variance of $a_i$,

$~~~~~~\sigma^2_{b_1}$ is variance of $b_{1i}$,

$~~~~~~\sigma_{ab_1}$ is covariance of $a_i$ and $b_{1i}$,

$~~~~~~\sigma_\varepsilon^2$ is error variance. 

### Fitting the model `qm_ris`

```{r}
qm_ris <- glmmTMB(temperature ~ poly(depth,2) + (depth | location), temp)
summary(qm_ris)
```

The residual standard deviation is down from `r round(sigma( qm_ri), 2)` to `r round(sigma(qm_ris), 2)`. The AIC score is down from `r round(AIC( qm_ri), 1)` to `r round(AIC(qm_ris), 1)`!

The likelihood ratio tests clearly favour the increasingly complex models that we've been fitting.

```{r}
anova(lm_ri,qm_ri,qm_ris)
```

### Interpreting random effects of location on the intercept and slope, and their correlation

Let's look at the random effects in this model.

```{r}
ranef(qm_ris)
```

Each line is a location. The first column gives us the effect of the locations on the intercept, and the second column gives us the effect of the locations on the slope. 

If you add the population-level intercept (16.0222) to the first column, you get the actual location-specific intercepts. If you add the population-level slope (-42.9959) to the second column, you get the actual location-specific slopes.

Let's do so.

```{r}
location_intercepts_and_slopes <- 
  ranef(qm_ris)$cond$location |> 
    transmute(
      `Location intercept` = `(Intercept)` + 16.0222,
      `Location slope` = `depth` + -42.9959 
    ) 

location_intercepts_and_slopes |> head()
```

These values don't make a lot of sense with respect to the actual raw values of $x$ and $y$. This is a consequence of our use of the `poly()` function to change the scale of $x$. 

In the summary output above, there is a high negative correlation (-0.93) between the random effects of location on the intercept and slope. This tells us that the locations that are warmer at the surface decline in temperature faster. This makes some sense. The temperature near the surface likely fluctuations more in the short term than the  temperature at depth.

We can see this if we plot the location-specific intercepts and slopes we calculated above.


```{r, fig.dim=c(8,8)}
location_intercepts_and_slopes |> 
  ggplot() + aes(x = `Location intercept`,
                 y = `Location slope`) +
  geom_point() +
  annotate(geom="text", x=22, y=-42.9, label="Correlation = -0.93") +
  ggtitle("Negative correlation between random effects",
          subtitle = "Locations that are warmer at the surface (high intercept) cool faster with depth (larger negative slope)")
```

What does this mean? In the plots of predictions in the next section, you can see that the lines the start higher decline faster, and the lines that start lower decline slower.

What happens if we remove the correlation parameter? Let's fit the model with the correlation removed (by putting the random intercepts and random slopes into separate terms in the formula) and compare the two models with a likelihood ratio test. 

```{r}
qm_ris_nocor <- 
  update(qm_ris, temperature ~ poly(depth,2) + (1|location) + (0+depth|location))

anova(qm_ris,qm_ris_nocor)
```

The `qm_ris` model (with correlated random effects of locations on intercept and slope) is clearly a big improvement over just having random intercepts. 


### Plotting the predictions and residuals of `qm_ris`

```{r, fig.dim=c(8,8)}
gw + geom_point() + geom_line(aes(y=predict(qm_ris)), col=2)  +
  ggtitle("Predictions by location")
```

```{r fig.dim=c(8,5)}
gt + 
  geom_line(aes(y=predict(qm_ris),col=location), alpha=.6) + 
  geom_point(aes(col=location), alpha = .6)  +
  ggtitle("Predictions")
```

This is obviously a much better fit. The lines are no longer parallel due to the random effect of locations on the linear slope. There is still no random effect of the quadratic slope though. 

Let's see the residuals.

```{r, fig.dim=c(8,8)}
gw + 
  geom_hline(yintercept = 0) +
  geom_point(aes(y=residuals(qm_ris))) +
  ggtitle("Residuals by location")
```

Hmm, we're definitely not there yet! We need to see as little pattern in the residuals as possible. The above plot shows that the amount of curvature in the decline in temperature with depth varies among locations. So, let's put this in the model.


## Model 1.4: Polynomial model with random effects on all three terms (intercept, linear, quadratic) (`qm_rq`)


### Mathematical description of model `qm_rq`

$$
y_{ij} = \alpha + a_i + \beta_1 x_{ij} + b_{1i} x_{ij} + \beta_2 x^2_{ij}  + b_{2i} x^2_{ij} + \varepsilon_{ij} \\
\begin{equation}
\begin{bmatrix}
  a_i \\
  b_{1i} \\
  b_{2i}
  \end{bmatrix}
\sim \text{MVN}(\begin{bmatrix}
  0 \\
  0 \\
  0 \\
  \end{bmatrix},
\begin{bmatrix}
  \sigma^2_a \\
  \sigma_{ab_1} & \sigma^2_{b_1}\\
  \sigma_{ab_2} & \sigma_{b_1b_2} & \sigma^2_{b_2} \\
  \end{bmatrix}
)
\end{equation} \\
\varepsilon_{ij} \sim \text{N}(0,\sigma_\varepsilon^2)
$$

where

$~~~~~~y_{ij}$ is the temperature at location $i$, observation $j$,

$~~~~~~x_{ij}$ is the depth at location $i$, observation $j$,

$~~~~~~x^2_{ij}$ is the *squared* depth at location $i$, observation $j$,

$~~~~~~\alpha$ is the population-level intercept (overall mean of $y$ at $x=0$),

$~~~~~~\beta_1$ is the population-level slope for $x_{ij}$, the linear effect,

$~~~~~~\beta_2$ is the population-level slope for $x^2_{ij}$, the quadratic effect, 

$~~~~~~a_i$ are the random effects of locations on the intercept,

$~~~~~~b_{1i}$ are the random effects of locations on the linear term $x_{ij}$,

$~~~~~~b_{2i}$ are the random effects of locations on the quadratic term $x^2_{ij}$,

$~~~~~~\sigma_a^2$, $\sigma^2_{b_1}$, and $\sigma^2_{b_2}$ are the variances of $a_i$, $b_{1i}$, and $b_{2i}$, respectively,

$~~~~~~\sigma_{ab_1}$, $\sigma_{ab_2}$, and $\sigma_{b_1b_2}$ are the covariances of the pairs of random effects $a_i$, $b_{1i}$, and $b_{2i}$, and 

$~~~~~~\sigma_\varepsilon^2$ is error variance. 

Just for fun, here's an alternative way of writing this model.

$$
y_{ij} = \text{N}(\mu_{ij},\sigma_\varepsilon^2) \\
\mu_{ij} = a_{i} + b_{1i} x_{ij} + b_{2i} x^2_{ij} \\
\begin{equation}
\begin{bmatrix}
  a_i \\
  b_{1i} \\
  b_{2i}
  \end{bmatrix}
\sim \text{MVN}(\begin{bmatrix}
  \alpha \\
  \beta_1 \\
  \beta_2 \\
  \end{bmatrix},
\begin{bmatrix}
  \sigma^2_a \\
  \sigma_{ab_1} & \sigma^2_{b_1}\\
  \sigma_{ab_2} & \sigma_{b_1b_2} & \sigma^2_{b_2} \\
  \end{bmatrix}
)
\end{equation} 
$$

The only difference in the meanings of the parameters is that the random-effects parameters $a_i$, $b_{1i}$, and $b_{2i}$ are centred on the population means ($\alpha$, $\beta_1$, and $\beta_2$) rather than zero. They're the *actual* fitted intercepts, linear slopes, and quadratic slopes for each population, as opposed to the *deviations* from the population means to the location estimates. Otherwise, it's the same model. 

Oh, the $\mu_{ij}$ are the predicted values for each $y_{ij}$. The observations $y_{ij}$ come from a normal distribution with mean $\mu_{ij}$ and variance $\sigma^2_\varepsilon$. 

### Fitting model `qm_rq`

```{r}
qm_rq <- glmmTMB(temperature ~ poly(depth,2) + (poly(depth,2)|location), data=temp)
summary(qm_rq)
```

We have reduced the residual standard deviation from `r round(sigma(qm_ris), 2)` to `r round(sigma(qm_rq), 2)`, and the AIC from `r round(AIC( qm_ris), 1)` to `r round(AIC(qm_rq), 1)`. 

The correlation parameters are interesting too. The random effects on the intercept $a_i$ are negatively correlated with the random effects on the linear term $b_{1i}$ and positively correlated with the random effects on the quadratic term $b_{2i}$, and $b_{1i}$ and $b_{2i}$ are negatively correlated. What does this mean?


At locations that are cooler at the surface:

- temperature decreases faster with depth, and

- there is less curvature in the decrease in temperature with depth. 

At locations that are warmer at the surface:

- temperature decreases slow with depth, and

- there is more curvature in the decrease in temperature with depth. 


Here are those random-effects terms and how they're related to each other.

```{r}
tibble(Intercept = ranef(qm_rq)$cond$location[,1],
       Linear = ranef(qm_rq)$cond$location[,2],
       Quadratic = ranef(qm_rq)$cond$location[,3] ) |> 
  GGally::ggpairs() +
  ggtitle("Relationships between random effects")
```

We have fit an *unstructured* variance-covariance matrix to these random effects, which allows each variance and covariance to be estimated separately, and it looks as if it is necessary.


### Plotting the predictions and residuals from model `qm_rq`

```{r, fig.dim=c(8,8)}
gw + geom_point() + geom_line(aes(y=predict(qm_rq)), col=2)  +
  ggtitle("Predictions by location")
```

```{r fig.dim=c(8,5)}
gt + 
  geom_line(aes(y=predict(qm_rq),col=location), alpha=.6) + 
  geom_point(aes(col=location), alpha = .6)  +
  ggtitle("Predictions")
```


This is obviously a much better fit. 

Let's see the residuals. This time, we'll add a band of 2 times the estimated residual standard deviation - 95% of residuals should be within this band.

```{r, fig.dim=c(8,8)}
gw + 
  geom_ribbon(aes(ymin = - 2 * sigma(qm_rq), 
                  ymax = + 2 * sigma(qm_rq)), 
              fill = 4, alpha = .4) +
  geom_hline(yintercept = 0) +
  geom_point(aes(y=residuals(qm_rq)))  +
  ggtitle("Residuals by location (with 95% coverage bands)")
  
```


There's not a lot of pattern in the residuals now. But, one can see some heterogeneity in the residual variance among locations. The model expects the variance of the residuals to be constant across locations, as indicated by the blue ribbons. But some locations' residuals are more variable than others. This is heteroscedasticity. Heteroscedasticity is bad. It breaks a major assumption of our linear model. 

Let's explore this idea a little further.

### Analysis of residuals vs temperature

```{r}
temp |> 
  mutate(residuals = residuals(qm_rq)) |> 
  group_by(location) |> 
  summarise(`SD residuals` = sd(residuals)) |> 
  ggplot() +
  aes(x=location, y = `SD residuals`) +
  geom_point() +
  ggtitle("Std deviation of residuals by location") +
  xlab("Locations (ordered by their mean temperatures)")
```

At the start, the locations were ordered by their mean temperatures. Location 1 has the lowest mean temperature; location 56 the highest.

Let's go ahead and plot this relationship directly.

```{r}
temp |> 
  mutate(residuals = residuals(qm_rq)) |> 
  group_by(location) |> 
  summarise(`SD of the residuals` = sd(residuals),
            `Mean temperature` = mean(temperature)) |> 
  ggplot() +
  aes(x=`Mean temperature`, y = `SD of the residuals`) +
  geom_point() +
  geom_smooth() +
  ggtitle("Std deviation of residuals by mean temperature, per location")
```


There's definitely a correlation there. The higher-temperature locations have greater residual variance. 

### Analysis of residuals vs depth

Another way to think about this is that the variance of location effects is changes across the different depths.

We saw this in the first plot we made.

```{r}
gt + geom_jitter(width = 0.5, alpha = .4)
```

If we look at the residuals from the current model across depths, we can see that the variance of the residuals does differ among depths; it is much higher at depths 5 and 10 than it is at depth 30. Interestingly, locations with high residual at depth 5 had low residual at depth 10. 

```{r}
temp |> 
  mutate(residuals = residuals(qm_rq)) |> 
  ggplot() +
  aes(x=depth, y = residuals) + 
  geom_point(aes(col=location),alpha=.3)  +
  geom_line(aes(group=location, col=location),alpha=.3)  +
  geom_boxplot(aes(group=depth), alpha=0) +
  ggtitle("Residuals by depth, coloured by location") +
  theme(legend.position="none")
```

Perhaps our fully-varying polynomial model is not doing as well as we'd thought. Let's rethink our approach.


# Models that treat depth as continuous for fixed effects and categorical for random effects

In this set of models, we will keep the population-level polynomial fit of temperature to depth, but we'll make a substantial change to the random part of the model, the part that deals with the differences among locations.  

For the random part of the model, instead of treating depth as continuous and adjusting the polynomial coefficients to each location, we will treat depth as a factor and ***fit a different random effect for each location within each depth stratum***. That is, each location will have a random effect for depth 5, a random effect for depth 10, ..., and a random effect for depth 30. 

The random effects will have different variances for different depths. 

Further, because some locations have consistently higher-than-average temperatures, and others have consistently lower-than-average temperatures, we will allow the random effects of locations to be correlated between pairs of depth strata. 

Because there is no replication at the lowest level (there is only one measurement from each location at each depth), these depth-by-location random effects will replace the error term. The error term must therefore be removed.

We will fit two variants of this model, each with a different variance-covariance structure for the random effects of location with respect to the depth categories.


## Model 2.1: Fixed polynomial model of depth and depth-specific random effects of locations with **unstructured correlation matrix** (`qm_rf_us`)

### Mathematical description of model `qm_rf_us`

The population-level part of this model is the same polynomial function of depth as a continuous predictor. 

We have removed the random effects of location on the intercept and polynomial terms, and the error term, and replaced this with depth-and-location-specific random effects $a_{\text{location }i, \text{ depth }j}$, with unstructured variance-covariance matrix.

$$
y_{ij} = \alpha + \beta_1 x_{j} + \beta_2 x^2_{j} + a_{ij} \\
\begin{equation}
\begin{bmatrix}
  a_{i1} \\
  a_{i2} \\
  a_{i3} \\
  a_{i4} \\
  a_{i5} \\
  a_{i6} 
  \end{bmatrix}
\sim \text{MVN}(\begin{bmatrix}
  0 \\
  0 \\
  0 \\
  0 \\
  0 \\
  0 \\
  \end{bmatrix},
\begin{bmatrix}
  \sigma^2_1 \\
  \sigma_{12} & \sigma^2_{2}\\
  \sigma_{13} & \sigma_{23} & \sigma^2_{3} \\
  \sigma_{14} & \sigma_{24} &  \sigma_{34} & \sigma^2_{4} \\
  \sigma_{15} & \sigma_{25} &  \sigma_{35} &  \sigma_{45} & \sigma^2_{5} \\
  \sigma_{16} & \sigma_{26} &  \sigma_{36} &  \sigma_{46} &  \sigma_{56} & \sigma^2_{6} \\  \end{bmatrix}
)
\end{equation} \\
$$

where

$~~~~~~i$ is an index for location (1,2,...,56),

$~~~~~~j$ is an index from 1 to 6 identifying the six depth strata (depth $x_1$ = 5, depth $x_2$ = 10, ..., depth $x_6$ = 30),

$~~~~~~y_{ij}$ is the temperature at location $i$, depth stratum $j$,

$~~~~~~x_{j}$ is the depth at depth stratum $j$,

$~~~~~~x^2_{j}$ is the square of depth $x_j$,

$~~~~~~\alpha$ is the population-level intercept (overall mean of $y$ at $x=0$),

$~~~~~~\beta_1$ is the population-level slope for the linear effect of depth $x_{j}$,

$~~~~~~\beta_2$ is the population-level slope for the quadratic effect of depth $x^2_{j}$,

$~~~~~~a_{ij}$ is the random effect of locations $i$ in depth stratum $j$,

$~~~~~~\sigma_1^2$ is the variance of random location effects $a_{i1}$ in depth stratum $1$ (depth = 5), 

$~~~~~~\sigma^2_{2}$ is the variance of random location effects $a_{i2}$ in depth stratum $2$ (depth = 10), 

$~~~~~~...$,

$~~~~~~\sigma_{12}=\text{Cov}(a_{i1},a_{i2})$, the covariance of random location effects between depth stratum $1$ (depth 5) and depth stratum $2$ (depth 10),

$~~~~~~\sigma_{13}=\text{Cov}(a_{i1},a_{i3})$, the covariance of random location effects between depth stratum $1$ (depth 5) and depth stratum $3$ (depth 15),

$~~~~~~...$.

The unstructured variance-covariance matrix means that a different variance is estimated for each depth stratum ($\sigma^2_j$) and a different covariance is estimated for each pair of depth strata ($\sigma_{jk}$ for $j \neq k$.)

Notice that we removed the error term. We have random effects of each location at each depth. With no replication at the lowest level, there is nothing more for an error term to do.


### Fitting model `qm_rf_us`

```{r eval=TRUE, include=TRUE}
# define Depth, a factor version of depth
qm_rf_us <- glmmTMB(temperature ~ poly(depth,2) + 
                          us(0 + factor(depth) | location),
                          dispformula = ~ 0,
                    data = temp)
```

`us(0 + as_factor(depth) | location)` gives us an unstructured var-cov matrix for the random effects of location for each level of the depth factor.

`dispformula = ~ 0` removes the error term. 

Now let's summarise the model.

```{r eval=TRUE, include=TRUE}
# fitting again with factor(depth) pre-prepared because the output of summary() is nicer
glmmTMB(temperature ~ poly(depth,2) + 
                          us(0 + Depth | location),
                          dispformula = ~ 0,
                    data = temp |> mutate(Depth = as_factor(depth))) |> 
  summary()
```

Wow, look at that drop in AIC! This is a much stronger model than the others. 

### Interpreting the random effects of model `qm_rf_us`

So now, we have a random effect **for each location for each depth stratum**.

Here are those effects for the  first 10 locations.

```{r}
round(ranef(qm_rf_us)$cond$location,2) |> head(10)
```

Here is the variance-covariance matrix (represented by standard deviations and correlations).

```{r}
VarCorr(qm_rf_us)
```

The `Std.Dev.` represent the standard deviations of location effects within each depth stratum. For example, the location effects have a standard deviation of 1.64 in the Depth5 stratum. This means that the average location differs from what is predicted given the population-polynomial model by 1.64 degrees. The standard deviation of location effects in the Depth10 stratum is 1.47, etc. The variability among locations starts off high near the surface and decreases with depth.

The triangle of `Corr` values are the correlations of the location effects for each pair of depth strata. They tell us how similar the random effects of location are between the depth strata. If the warmest locations at Depth5 are also the warmest locations at Depth10, then this is reflected by a high positive correlation for these two strata.

There is an interesting pattern in these correlations. They are strongest just below the diagonal, and get weaker towards the bottom-right corner. This tells us that the correlations are related to the difference in depth. Adjacent depth strata (strata that are only 5 units apart) are most strongly correlated (e.g., $\rho_{12}=0.927$, $\rho_{23}=0.962$, ..., $\rho_{56}=0.927$). That is, if a location is relatively warm at Depth15, that same location will likely also be warm at Depth10 and Depth20. Then, correlations are quite strong for depth strata that are two steps (10 units) apart, a little less for three steps (15 units), ..., until finally there is only a weak correlation in the location effects between Depth5 and Depth30 ($\rho_{16}=0.074$). 

We can see this quite clearly in the plot of the random effects below. 

```{r message=FALSE, fig.dim=c(8,8)}
ranef(qm_rf_us)$cond$location |> 
  GGally::ggpairs() +
  ggtitle("Location random effects by depth stratum")

```

### Plotting predictions and residuals of model `qm_rf_us`

Let's make the usual plot.

```{r, fig.dim=c(8,8)}
gw + geom_point() + 
  geom_line(aes(y=predict(qm_rf_us)), col=2)  +
  ggtitle("Predictions by location")
```

This is a little bit cheating, because we are essentially including the error term in our predictions. The error term for this model *is* the random effects, and the random effects are used in the predictions. 

Here's a plot of the profiles showing the population-level fit in black.

```{r fig.dim=c(8,5)}

preds_qm_rf_us <- predict(qm_rf_us, re.form = NA, se.fit = TRUE) |> 
  as_tibble() |> 
  mutate(depth = temp$depth) |> 
  distinct(depth, .keep_all= TRUE) |> 
  mutate(conf.low=fit-2*se.fit,
         conf.high=fit+2*se.fit)

gt + 
  geom_line(aes(col=location), alpha=.6) + 
  geom_point(aes(col=location), alpha = .6) +
  geom_ribbon(aes(x=depth, ymin=conf.low, ymax=conf.high), inherit.aes = F,
    data=preds_qm_rf_us, alpha=.6) +
  geom_line(aes(y=fit), lwd=1.2, data=preds_qm_rf_us) +
  ggtitle("Predictions")
```


Let's see the residual plot, with updated error structure. The residuals for this model are really just the depth-specific location effects. All three of the plots below will show the location effects for each depth, after accounting for the population-level polynomial model of the decline in temperature with depth. 

First we need to dig out the random effects for each location at each depth (`loc_effects`), and the standard deviations of the location effects for each depth (`depth_sd`).

```{r, fig.dim=c(8,8)}
# Extract location effects for each depth
loc_effects <- ranef(qm_rf_us)$cond$location |> 
  data.frame() |> 
  rownames_to_column("location") |> mutate(location = as_factor(location)) |> 
  pivot_longer(factor.depth.5:factor.depth.30, names_to="Depth", values_to="Effects") |> 
  mutate(depth = substring(Depth,14,16) |> as.numeric())

# Extract estimates of SD of location effects for each depth
depth_sd <- confint(qm_rf_us) |> 
  data.frame() |> 
  rownames_to_column("Parameter") |> 
  dplyr::filter(str_detect(Parameter, "Std")) |> 
  mutate(depth = readr::parse_number(substring(Parameter,22,24))) |> 
  transmute(depth, SD_location = Estimate)
```

And now we can plot them.

```{r, fig.dim=c(8,8)}
# Add them to temp and plot
temp |> 
  right_join(depth_sd, by="depth") |> 
  right_join(loc_effects, by=c("location","depth")) |> 
  ggplot() +
  aes(x=depth) + facet_wrap(~location) +
  geom_ribbon(aes(ymin = - 2 * SD_location, 
                  ymax = + 2 * SD_location), 
              fill = 4, alpha = .4) +
  geom_hline(yintercept = 0) +
  geom_point(aes(y=Effects)) +
  ggtitle("Location effects vs depth by location")
```

We can see that the SD of the location effects (represented by the blue bands) declines with depth - there's less variation among locations at deeper depths. Most of the effects are within the bands. Some locations have all their points outside the bands, but that's OK, because we expect the within-location effects to be correlated across depths. 

```{r}
temp |> 
  right_join(depth_sd, by="depth") |> 
  right_join(loc_effects, by=c("location","depth")) |> 
  ggplot() +
  aes(x=depth, y = Effects) + 
  geom_hline(yintercept = 0) +
  geom_ribbon(aes(ymin = - 2 * SD_location, 
                  ymax = + 2 * SD_location), 
              alpha = .2) +
  geom_point(aes(col=location),alpha=.3)  +
  geom_line(aes(group=location, col=location),alpha=.3)  +
  geom_boxplot(aes(group=depth), alpha=0) +
  ggtitle("Location effects by depth, coloured by location") +
  theme(legend.position="none")
```

These plots show our model of the variation in temperature among locations across the depths, after accounting for the overall (polynomial) decline in temperature that occurs across all locations. 

- Each set of points and line represent the random effects of a location across the depths. 

- The grey band represents (2 times) the estimated standard deviations of the location effects for each depth. 95% of the effects should be within the grey band. The narrowing reflects the decrease in variance of the location effects with increasing depth. Only a few locations have points outside the band, which is good. It's a 95% interval, and we have 56 locations, so we expect about three or so to be outside the band. 

- The effects of each location look quit consistent across the depths. This reflects the positive correlations in the variance-covariance structure of the location effects.

Is this model better than the previous location-adjusted polynomial one?

```{r}
anova(qm_rq,qm_rf_us)
```

Clearly, yes.

This model has a lot more parameters though, with all those individual variances and covariances. Let's try a slightly simpler version.


## Model 2.2: Fixed polynomial model of depth and depth-specific random effects of locations with **Toeplitz correlation matrix** (`qm_rf_toep`)

### Mathematical description of model `qm_rf_toep`

This model is the same as `qm_rf_us`, except it has a slightly different covariance structure (The variance structure is the same - each depth stratum gets its own variance of location effects.)

It's easier to express the change in terms of a matrix of correlations $\rho_{ij}$ between depth strata $j$ and $k$ for $j\neq k$, rather than covariances, as per below.

$$
\begin{bmatrix}
  \rho_{12} \\
  \rho_{13} & \rho_{23} \\
  \rho_{14} & \rho_{24} &  \rho_{34}  \\
  \rho_{15} & \rho_{25} &  \rho_{35} &  \rho_{45}\\
  \rho_{16} & \rho_{26} &  \rho_{36} &  \rho_{46} &  \rho_{56}  \\  
\end{bmatrix}
$$

**The Toeplitz condition is that the correlations between pairs of depths that are the same distance apart are identical.**


$$
\rho_{12} = \rho_{23} = \rho_{34} = \rho_{45} = \rho_{56} \\
\rho_{13} = \rho_{24} = \rho_{35} = \rho_{46} \\
\rho_{14} = \rho_{25} = \rho_{36}  \\
\rho_{15} = \rho_{26} \\
\rho_{16}
$$

- The correlations of location effects between adjacent depth strata are identical. That is, $\rho_{12}$, the correlation of location effects between depths 5 and 10, is equal to $\rho_{23}$, the correlation of location effects between depths 10 and 15, is equal to ..., is equal to $\rho_{56}$, the correlation of location effects between depths 25 and 30. 

- The correlations of location effects between depth strata two steps apart are also identical. That is, $\rho_{13}$ equals $\rho_{24}$ equals ... equals $\rho_{46}$.

    ...

- The correlations of location effects between depth strata four steps apart are also identical. That is, $\rho_{15}$ equals $\rho_{26}$.

- The correlation between depth strata 1 and 6 ($\rho_{16}$) is unconstrained.


The Toeplitz structure is slightly more restrictive, but it requires fewer parameters. We only need 5 unique correlation parameters, half the number required by the unstructured-correlation model `qm_rf_us`.

### Fitting model `qm_rf_toep`

```{r eval=TRUE, warning=FALSE, include=TRUE}
qm_rf_toep <- glmmTMB(temperature ~ poly(depth,2) + 
                         toep(0 + factor(depth) | location),
                         dispformula = ~ 0,
                         data = temp)
```


```{r eval=TRUE, warning=FALSE, include=TRUE}
# fitting again with factor(depth) pre-prepared because the output of summary() is nicer
glmmTMB(temperature ~ poly(depth,2) + 
                          toep(0 + Depth | location),
                          dispformula = ~ 0,
                    data = temp |> mutate(Depth = as_factor(depth))) |> 
  summary()
```

See how the correlations are identical along the diagonal bands? 

Let's see if the Toeplitz structure is a better fit than the unstructured structure.

```{r}
anova(qm_rf_us, qm_rf_toep)
```
In the unstructured-correlation model `qm_rf_us`, we saw that the between-depth correlations in location effects were quite strongly related to the distances between depths. So, we tried to put that pattern into model `qm_rf_toep`. However, the unstructured model is clearly a better fit to the data. 


# Summary

This has largely been process of starting with relatively simple models, looking at the fits and residuals, identifying patterns in the residuals, and adding terms to the next model to try to move those patterns from the residuals to the model. In order to fully trust a the inferences or predictions of a model, there needs to be no or negligible patterns in the residuals.

Let's do a final comparison of all the models. 

```{r}
anova(lm_ri, qm_ri, qm_ris, qm_rq, qm_rf_toep, qm_rf_us) 
```

The first four models, `lm_ri` to `qm_rq`, had linear or polynomial fits of temperature to depth at the population-level. The random effects of location were essentially adjustments to the two or three coefficients of the population-level model according to the trajectory of temperature with depth within each location.

The final two models, `qm_rf_us` and `qm_rf_toep`, took a different approach to the random effects of location. Like all the `qm_` models, they were based on a population-level polynomial of temperature with depth. For the random part of the model, the random effects were not used to adjust the slope coefficients for depth. Instead, depth was treated as a categorical factor, and the random location effects were allowed to be *different but correlated* among the depth categories, and to have different variances among depths. 

With the two `qm_rf` models, we used different structures for the matrix of between-depth correlations in the location effects. The model `qm_rf_us` fit an unstructured correlation matrix - the correlations of the location effects for each pair of depth categories had no structure imposed, and were estimated freely, irrespective of the order of the depths. In contrast, the Toeplitz correlation structure (`qm_rf_toep`) fixed the correlations of the location effects to be identical for pairs of depths that were the same distance apart. 

By the AIC and likelihood ratio tests, the best model, by far, was the most complicated one: `qm_rf_us`. 

In general, once the models get this complicated (actually much before!), I tend to favour Bayesian approaches to mixed models due to their flexibility and ease of interpretation. The Bayesian approach is quite technical though, and it is beyond the scope of this course.

What have we learned? 

Trivial findings:

1. Temperature of the soil declines with depth. This relationship is not strictly linear; the decline slows down at deeper depths. 

2. Temperature profiles vary among locations.

What is the best way to conceive of this system?

The two conceptual models we explored with these data can be described as follows:

1. On average, across locations, there's a polynomial relationship between temperature and depth. This relationship has three coefficients: an intercept, a slope for the linear (straight line) effect, and a slope for the quadratic (curvy) effect. These coefficients vary randomly among locations. 

2. On average, across locations, there's a polynomial relationship between temperature and depth with the same three coefficients. Around this relationship, temperatures vary among locations, more so at shallower than deeper depths. Locations that are warmer (or cooler) at a particular depth tend to also be warmer (or cooler) at other, especially similar, depths.  

Conceptual model 1 is represented by the statistical model `qm_rq`. Conceptual model 2 is represented by the statistical models `qm_rf_us` and `qm_rf_toep`. 

Given that the much better fit of statistical models `qm_rf_us` and `qm_rf_toep`, the second of the above conceptual models is likely a better description of how soil temperature declines with depth at different locations.
